# LLMServer 로컬 개발 환경
version: '3.8'

services:
  llmserver:
    build: .
    container_name: llmserver-dev
    ports:
      - "8000:8000"
    environment:
      - AI_PROVIDER=${AI_PROVIDER:-mock}
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - OPENAI_MODEL=${OPENAI_MODEL:-gpt-4o-mini}
      - OPENAI_MAX_TOKENS=${OPENAI_MAX_TOKENS:-2000}
      - CLAUDE_API_KEY=${CLAUDE_API_KEY:-}
      - CLAUDE_MODEL=${CLAUDE_MODEL:-claude-3-haiku-20240307}
      - REQUEST_LIMIT_PER_HOUR=${REQUEST_LIMIT_PER_HOUR:-50}
      - REQUEST_LIMIT_PER_DAY=${REQUEST_LIMIT_PER_DAY:-500}
      - USE_CACHE=${USE_CACHE:-true}
      - CACHE_TTL=${CACHE_TTL:-7200}
      - REDIS_URL=redis://redis:6379
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - TZ=Asia/Seoul
    volumes:
      - /etc/localtime:/etc/localtime:ro
    depends_on:
      - redis
    networks:
      - llmserver-net

  redis:
    image: redis:7-alpine
    container_name: redis-llm-dev
    command: redis-server --requirepass ${REDIS_PASSWORD:-password}
    ports:
      - "6379:6379"
    environment:
      - TZ=Asia/Seoul
    volumes:
      - /etc/localtime:/etc/localtime:ro
    networks:
      - llmserver-net

networks:
  llmserver-net:
    driver: bridge
